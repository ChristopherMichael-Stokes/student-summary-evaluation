{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import ngrams\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numba\n",
    "import joblib\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from joblib import Parallel, delayed\n",
    "import plotly.express as px\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import GroupKFold, HalvingRandomSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import lightgbm as lgb\n",
    "from math import sqrt\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Optional, Union, List, Tuple"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- add sentence embedding -> clustering with cluster ID as a categorical feature\n",
    "\n",
    "^ might not work actually as the train set is smaller than our test set + has less unique prompts meaning the clusters will not be very transferrable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatiser = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('../data')\n",
    "\n",
    "sample_submission = data_dir / 'sample_submission.csv'\n",
    "summaries_train = data_dir / 'summaries_train.csv'\n",
    "summaries_test = data_dir / 'summaries_test.csv'\n",
    "prompts_train = data_dir / 'prompts_train.csv'\n",
    "prompts_test = data_dir / 'prompts_test.csv'\n",
    "\n",
    "def make_split(summaries_path: Path, prompts_path: Path, dtype_backend: Optional[str] = 'pyarrow') -> pd.DataFrame:\n",
    "    summaries_df = pd.read_csv(summaries_path, dtype_backend=dtype_backend)\n",
    "    prompts_df = pd.read_csv(prompts_path, dtype_backend=dtype_backend)\n",
    "    df = pd.merge(summaries_df, prompts_df, how='inner', on='prompt_id')\n",
    "\n",
    "    if len(df) != len(summaries_df):\n",
    "        raise AssertionError('Could not match all prompt ids to a prompt')\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = make_split(summaries_train, prompts_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_stopwords(column: pd.Series, idx: int) -> Union[List[str], List[str], List[str], List[str], List[str]]:\n",
    "    tokens = [tok.lower() for tok in word_tokenize(column.iloc[idx]) if tok.isalnum()]\n",
    "    cleared_stopwords = [tok for tok in tokens if tok not in stop_words]\n",
    "    lemmas = [lemmatiser.lemmatize(tok) for tok in cleared_stopwords]\n",
    "    bigram = set(ngrams(lemmas, 2))\n",
    "    tri_gram = set(ngrams(lemmas, 3))\n",
    "    four_gram = set(ngrams(lemmas, 4))\n",
    "\n",
    "    return tokens, cleared_stopwords, lemmas, bigram, tri_gram, four_gram\n",
    "\n",
    "def nlp_splits(df: pd.DataFrame, column: str) -> None:\n",
    "    output = Parallel(n_jobs=4)(delayed(clear_stopwords)(df[column], idx) for idx in range(len(df)))\n",
    "\n",
    "    df[f'{column}_tokens'] = [part[0] for part in output]\n",
    "    df[f'{column}_no_stopwords'] = [part[1] for part in output]\n",
    "    df[f'{column}_lemmas'] = [part[2] for part in output]\n",
    "    df[f'{column}_bigram'] = [part[3] for part in output]\n",
    "    df[f'{column}_trigram'] = [part[4] for part in output]\n",
    "    df[f'{column}_fourgram'] = [part[5] for part in output]\n",
    "\n",
    "x = clear_stopwords(df.text, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_columns = ['prompt_title', 'prompt_question', 'prompt_text', 'text']\n",
    "for column in text_columns:\n",
    "    nlp_splits(df, column)\n",
    "    df[f'{column}_unique_bigrams'] = df[f'{column}_bigram'].str.len()\n",
    "    df[f'{column}_unique_trigrams'] = df[f'{column}_trigram'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_bigram_overlap'] = df[['prompt_text_bigram', 'text_bigram']].apply(lambda row: len(row[0] & row[1]), axis=1)\n",
    "df['question_bigram_overlap'] = df[['prompt_question_bigram', 'text_bigram']].apply(lambda row: len(row[0] & row[1]), axis=1)\n",
    "df['title_bigram_overlap'] = df[['prompt_title_bigram', 'text_bigram']].apply(lambda row: len(row[0] & row[1]), axis=1)\n",
    "\n",
    "df['text_bigram_diff'] = df[['prompt_text_bigram', 'text_bigram']].apply(lambda row: len(row[0] - row[1]), axis=1)\n",
    "df['question_bigram_diff'] = df[['prompt_question_bigram', 'text_bigram']].apply(lambda row: len(row[0] - row[1]), axis=1)\n",
    "df['title_bigram_diff'] = df[['prompt_title_bigram', 'text_bigram']].apply(lambda row: len(row[0] - row[1]), axis=1)\n",
    "\n",
    "df['text_bigram_exclusive'] = df[['prompt_text_bigram', 'text_bigram']].apply(lambda row: len(row[0] ^ row[1]), axis=1)\n",
    "df['question_bigram_exclusive'] = df[['prompt_question_bigram', 'text_bigram']].apply(lambda row: len(row[0] ^ row[1]), axis=1)\n",
    "df['title_bigram_exclusive'] = df[['prompt_title_bigram', 'text_bigram']].apply(lambda row: len(row[0] ^ row[1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = df.select_dtypes(include=np.number)\n",
    "corr = numeric_features.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(include=np.number).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = ['content', 'wording']\n",
    "feature_columns = [col for col in numeric_features if col not in target_columns]\n",
    "\n",
    "targets = numeric_features[target_columns]\n",
    "features = numeric_features[feature_columns]\n",
    "prompt_group = pd.Categorical(df['prompt_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_group.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import GroupKFold, HalvingRandomSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import lightgbm as lgb\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=prompt_group.unique().size)\n",
    "group_kfold.get_n_splits(features, targets, prompt_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HistGradientBoostingRegressor(learning_rate=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_errors(y, y_pred):\n",
    "    return {\n",
    "        'r2': r2_score(y, y_pred),\n",
    "        'rmse': sqrt(mean_squared_error(y, y_pred)),\n",
    "        'mae': mean_absolute_error(y, y_pred)\n",
    "    }\n",
    "\n",
    "def train_kfold(target: str, prompt_group: pd.DataFrame, features: pd.DataFrame, targets: pd.DataFrame, model_params: dict) -> pd.DataFrame:\n",
    "    model = HistGradientBoostingRegressor(**model_params)\n",
    "\n",
    "    group_kfold = GroupKFold(n_splits=prompt_group.unique().size)\n",
    "    assert group_kfold.get_n_splits(features, targets, prompt_group) == len(prompt_group.unique())\n",
    "\n",
    "    train_errors, val_errors = [], []\n",
    "    for i, (train_index, test_index) in enumerate(group_kfold.split(features, targets, prompt_group)):\n",
    "        print(f'Fold {i}')\n",
    "        print(f'\\tTest prompt: {df.iloc[test_index].prompt_title.unique()}')\n",
    "\n",
    "        X_train = features.iloc[train_index]\n",
    "        y_train = targets.iloc[train_index][target]\n",
    "\n",
    "        X_val = features.iloc[test_index]\n",
    "        y_val = targets.iloc[test_index][target]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        train_errors.append(calculate_errors(y_train, model.predict(X_train)))\n",
    "        val_errors.append(calculate_errors(y_val, model.predict(X_val)))\n",
    "        print(model.predict(X_train))\n",
    "\n",
    "    train_metrics = pd.DataFrame.from_records(train_errors).describe()\n",
    "    train_metrics['set'] = 'train'\n",
    "    val_metrics = pd.DataFrame.from_records(val_errors).describe()\n",
    "    val_metrics['set'] = 'val'\n",
    "    metric_df = pd.concat([train_metrics, val_metrics])\n",
    "\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = train_kfold('content', prompt_group, features, targets, {})\n",
    "metric_df.loc[['mean', 'std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = train_kfold('wording', prompt_group, features, targets, {})\n",
    "metric_df.loc[['mean', 'std']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
